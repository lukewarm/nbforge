{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Input parameters\n",
    "input_file: str = \"data/raw/sample.csv\"  # {\"description\": \"Path to input CSV file\", \"input_type\": \"file\"}\n",
    "output_file: str = \"data/processed/sample_processed.csv\"  # {\"description\": \"Path to output CSV file\"}\n",
    "\n",
    "# Preprocessing options\n",
    "remove_duplicates: bool = True  # {\"description\": \"Remove duplicate rows\"}\n",
    "fill_missing: bool = True  # {\"description\": \"Fill missing values\"}\n",
    "fill_method: str = \"mean\"  # {\"description\": \"Method to fill missing values\", \"input_type\": \"select\", \"options\": [\"mean\", \"median\", \"mode\", \"zero\"]}\n",
    "normalize_columns: list = []  # {\"description\": \"Columns to normalize\", \"input_type\": \"multiselect\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os\n",
    "\n",
    "# Create a sample dataset if input file doesn't exist\n",
    "if not os.path.exists(input_file):\n",
    "    print(f\"Input file {input_file} not found. Creating sample data.\")\n",
    "    # Create directory if it doesn't exist\n",
    "    os.makedirs(os.path.dirname(input_file), exist_ok=True)\n",
    "    \n",
    "    # Generate sample data\n",
    "    np.random.seed(42)\n",
    "    data = {\n",
    "        'id': range(1, 101),\n",
    "        'value1': np.random.normal(100, 15, 100),\n",
    "        'value2': np.random.normal(50, 10, 100),\n",
    "        'category': np.random.choice(['A', 'B', 'C'], 100)\n",
    "    }\n",
    "    \n",
    "    # Add some missing values\n",
    "    data['value1'][np.random.choice(100, 10)] = np.nan\n",
    "    data['value2'][np.random.choice(100, 10)] = np.nan\n",
    "    \n",
    "    # Add some duplicates\n",
    "    for i in range(5):\n",
    "        idx = np.random.randint(0, 95)\n",
    "        data['id'][idx+5] = data['id'][idx]\n",
    "        data['value1'][idx+5] = data['value1'][idx]\n",
    "        data['value2'][idx+5] = data['value2'][idx]\n",
    "        data['category'][idx+5] = data['category'][idx]\n",
    "    \n",
    "    # Create DataFrame and save to CSV\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(input_file, index=False)\n",
    "    print(f\"Sample data saved to {input_file}\")\n",
    "else:\n",
    "    print(f\"Loading data from {input_file}\")\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "# Display basic info\n",
    "print(\"\\nData Info:\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"Columns: {df.columns.tolist()}\")\n",
    "print(f\"Missing values:\\n{df.isnull().sum()}\")\n",
    "print(f\"Duplicate rows: {df.duplicated().sum()}\")\n",
    "\n",
    "# Remove duplicates if requested\n",
    "if remove_duplicates and df.duplicated().sum() > 0:\n",
    "    print(f\"\\nRemoving {df.duplicated().sum()} duplicate rows\")\n",
    "    df = df.drop_duplicates()\n",
    "\n",
    "# Fill missing values if requested\n",
    "if fill_missing and df.isnull().sum().sum() > 0:\n",
    "    print(f\"\\nFilling missing values using method: {fill_method}\")\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    \n",
    "    for col in numeric_cols:\n",
    "        if df[col].isnull().sum() > 0:\n",
    "            if fill_method == 'mean':\n",
    "                df[col] = df[col].fillna(df[col].mean())\n",
    "            elif fill_method == 'median':\n",
    "                df[col] = df[col].fillna(df[col].median())\n",
    "            elif fill_method == 'mode':\n",
    "                df[col] = df[col].fillna(df[col].mode()[0])\n",
    "            elif fill_method == 'zero':\n",
    "                df[col] = df[col].fillna(0)\n",
    "    \n",
    "    # For categorical columns, fill with mode\n",
    "    categorical_cols = df.select_dtypes(exclude=[np.number]).columns\n",
    "    for col in categorical_cols:\n",
    "        if df[col].isnull().sum() > 0:\n",
    "            df[col] = df[col].fillna(df[col].mode()[0])\n",
    "\n",
    "# Normalize columns if requested\n",
    "if normalize_columns:\n",
    "    print(f\"\\nNormalizing columns: {normalize_columns}\")\n",
    "    scaler = MinMaxScaler()\n",
    "    df[normalize_columns] = scaler.fit_transform(df[normalize_columns])\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "\n",
    "# Save processed data\n",
    "df.to_csv(output_file, index=False)\n",
    "print(f\"\\nProcessed data saved to {output_file}\")\n",
    "print(f\"Final shape: {df.shape}\")\n",
    "\n",
    "# Display sample of processed data\n",
    "print(\"\\nSample of processed data:\")\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "notebook_spec": {
   "description": "Clean and preprocess CSV data files",
   "name": "Data Preprocessing",
   "python_version": "3.9",
   "requirements": {
    "numpy": "1.24.0",
    "pandas": "2.0.0",
    "scikit-learn": "1.2.0"
   },
   "tags": [
    "preprocessing",
    "data-cleaning"
   ]
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
